{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from course_intro_ocr_t1.data import MidvPackage\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import patches\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "from  torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm.notebook import tqdm\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_number = 4\n",
    "device = torch.device(device=f'cuda:{gpu_number}')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/krotovan/Alexander/ocr/midv500_compressed')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_PATH = Path().absolute().parent.parent.parent /'Alexander'/'ocr' /'midv500_compressed'\n",
    "assert DATASET_PATH.exists(), DATASET_PATH.absolute()\n",
    "DATASET_PATH\n",
    "\n",
    "# DATASET_PATH = Path().absolute().parent.parent / 'midv500' / 'midv500_compressed'\n",
    "# assert DATASET_PATH.exists(), DATASET_PATH.absolute()\n",
    "\n",
    "# data_packs = MidvPackage.read_midv500_dataset(DATASET_PATH)\n",
    "# len(data_packs), type(data_packs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, course_intro_ocr_t1.data.MidvPackage)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Собираем список пакетов (MidvPackage) \n",
    "data_packs = MidvPackage.read_midv500_dataset(DATASET_PATH)\n",
    "len(data_packs), type(data_packs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cropper:\n",
    "    def __init__(self):\n",
    "        self.orb = cv2.ORB_create(nfeatures=2000)\n",
    "        \n",
    "    def preprocess_image(self, img):\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        return gray_img\n",
    "        \n",
    "    def detect_compute_keypoints_descriptors(self, img):\n",
    "        keypoints, descriptors = self.orb.detectAndCompute(img, None)\n",
    "        return keypoints, descriptors\n",
    "        \n",
    "    def match_keypoints(self, template_dscs, target_dscs):\n",
    "        bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "        matches = bf.match(template_dscs, target_dscs)\n",
    "        matches = sorted(matches, key = lambda x:x.distance)\n",
    "        return matches\n",
    "        \n",
    "    def find_homography(self, query_pts, train_pts):\n",
    "        homo, _ = cv2.findHomography(query_pts, train_pts, cv2.RANSAC, 5.0)\n",
    "        return homo\n",
    "        \n",
    "    def transform_angles(self, homo, template_img):\n",
    "        template_angles = np.array([[0, 0], [len(template_img[0]), 0], [len(template_img[0]), len(template_img)], [0, len(template_img)]], dtype=np.float32)[:, None]\n",
    "        transformed_angles = cv2.perspectiveTransform(template_angles, homo)\n",
    "        return transformed_angles\n",
    "        \n",
    "    def normalize_coordinates(self, angles, target_img):\n",
    "        return angles / np.array([len(target_img[0]), len(target_img)])\n",
    "        \n",
    "    def angles(self, template_img, target_img):\n",
    "        template_gray = self.preprocess_image(template_img)\n",
    "        target_gray = self.preprocess_image(target_img)\n",
    "        template_kpts, template_dscs = self.detect_compute_keypoints_descriptors(template_gray)\n",
    "        target_kpts, target_dscs = self.detect_compute_keypoints_descriptors(target_gray)\n",
    "        matches = self.match_keypoints(template_dscs, target_dscs)\n",
    "        homo = self.find_homography(np.array([template_kpts[m.queryIdx].pt for m in matches], dtype=np.float32)[:, None],\n",
    "                                       np.array([target_kpts[m.trainIdx].pt for m in matches], dtype=np.float32)[:, None])\n",
    "        transformed_angles = self.transform_angles(homo, template_img)\n",
    "        normalized_angles = self.normalize_coordinates(transformed_angles, target_img)\n",
    "        return normalized_angles\n",
    "\n",
    "    def process_data_packs(self, data_packs):\n",
    "        results_dict = {}\n",
    "        for dp in tqdm(data_packs):\n",
    "            for i in range(len(dp)):\n",
    "                if dp[i].is_test_split():\n",
    "                    try:\n",
    "                        results_dict[dp[i].unique_key] = self.angles(np.array(dp.template_item.image), np.array(dp[i].image))\n",
    "                    except Exception as exc:\n",
    "                        pass\n",
    "        return results_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 50/50 [03:26<00:00,  4.12s/it]\n"
     ]
    }
   ],
   "source": [
    "cropper = Cropper()\n",
    "results_dict = cropper.process_data_packs(data_packs)\n",
    "output_dict = {key: arr.squeeze() for key, arr in results_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crop accuracy: 0.9640\n"
     ]
    }
   ],
   "source": [
    "from course_intro_ocr_t1.metrics import dump_results_dict, measure_crop_accuracy\n",
    "\n",
    "dump_results_dict(results, Path() / 'pred.json')\n",
    "accuracy = measure_crop_accuracy(\n",
    "    Path() / 'pred.json',\n",
    "    Path() / 'gt.json'\n",
    ")\n",
    "print(f'Crop accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
