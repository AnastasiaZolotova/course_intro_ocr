{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0270546-c6e1-4f60-8e82-47a03b22a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f659d99-60d0-4d2d-b88b-61f07f84d844",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2685783b-d09e-4363-8031-3860fb7c4f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from course_intro_ocr_t1.data import MidvPackage\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch import nn\n",
    "import cv2\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pylab import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e291e6a-7d07-4bd5-9e13-b35e4eca5b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = Path().absolute().parent.parent / 'midv500_compressed'\n",
    "assert DATASET_PATH.exists(), DATASET_PATH.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94c3336d-e609-47fa-8b64-43bcb8d5092f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, course_intro_ocr_t1.data.MidvPackage)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Собираем список пакетов (MidvPackage) \n",
    "data_packs = MidvPackage.read_midv500_dataset(DATASET_PATH)\n",
    "len(data_packs), type(data_packs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf924d4-b02c-41cc-a197-26a0c57bcfb4",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "661e68ad-35c7-4f2b-8f85-861aad8d3567",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MIDVDataset(Dataset):\n",
    "    def __init__(self, dp, validation_flag=False):\n",
    "        self.dp = dp\n",
    "        self.data_idx = []\n",
    "        \n",
    "        for i in range(len(dp)):\n",
    "            for j in range(len(dp[i])):                \n",
    "                if validation_flag and dp[i][j].is_test_split():\n",
    "                    self.data_idx.append((i, j))\n",
    "                elif not validation_flag and not dp[i][j].is_test_split():\n",
    "                    self.data_idx.append((i, j))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_idx)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        i, j = self.data_idx[idx]\n",
    "\n",
    "        img = transforms.ToTensor()(np.array(self.dp[i][j].image))\n",
    "        \n",
    "        corner_coordinates = np.array(self.dp[i][j].gt_data['quad']).reshape(4, 2)\n",
    "        mask = cv2.fillConvexPoly(np.zeros(img.size()[1:]), corner_coordinates, 1)\n",
    "        img = transforms.Resize((256, 256))(img)\n",
    "        mask = transforms.ToTensor()(mask)\n",
    "        mask = mask.float()\n",
    "        mask = transforms.Resize((256, 256))(mask)\n",
    "                \n",
    "        return img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110a2103-2bb8-4147-be47-bf67a7a941f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10750 4250\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MIDVDataset(data_packs, False)\n",
    "valid_dataset = MIDVDataset(data_packs, True)\n",
    "print(len(train_dataset), len(valid_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af1dbd72-da7d-4117-b95a-61c70f52ba4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True,  drop_last=True)\n",
    "valid_loader = DataLoader(dataset=valid_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a83bb-c6c9-40a2-984c-ca37e9231598",
   "metadata": {},
   "source": [
    "### Crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eee003bb-e09b-4e20-85f4-6fea38817359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0014b1c2-666b-49bb-9d24-99042985bc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels=3, n_classes=1):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.inc = (DoubleConv(n_channels, 64))\n",
    "        self.down1 = (Down(64, 128))\n",
    "        self.down2 = (Down(128, 256))\n",
    "        self.down3 = (Down(256, 512))\n",
    "        self.down4 = (Down(512, 1024))\n",
    "        self.up1 = (Up(1024, 512))\n",
    "        self.up2 = (Up(512, 256))\n",
    "        self.up3 = (Up(256, 128))\n",
    "        self.up4 = (Up(128, 64))\n",
    "        self.outc = (OutConv(64, n_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f439ce13-c077-4564-8bbc-e5136bdb37e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fac0920f-4f9a-4a56-8255-7dfa7de32b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import lightning\n",
    "import torchmetrics\n",
    "\n",
    "class LitClassifier(lightning.LightningModule):\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.criterion = DiceLoss()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        inputs, targets = batch\n",
    "\n",
    "        outputs = self.model(inputs)\n",
    "        loss = self.criterion(outputs, targets)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(params=self.model.parameters(), lr=0.001)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb63a4f6-e138-4f0e-8a76-dcf1aaa33eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "29c94763-c714-43f8-860f-48fbc6285866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2024-10-11 18:23:27.952121: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-11 18:23:28.838685: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [6]\n",
      "\n",
      "  | Name      | Type     | Params\n",
      "---------------------------------------\n",
      "0 | model     | UNet     | 31.0 M\n",
      "1 | criterion | DiceLoss | 0     \n",
      "---------------------------------------\n",
      "31.0 M    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 M    Total params\n",
      "124.151   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                                                                            …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/krotovan/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n",
      "/home/krotovan/.local/lib/python3.10/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15e602f2d8b44198980d3803cc45c3fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                                                                                 …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=10` reached.\n"
     ]
    }
   ],
   "source": [
    "model = UNet()\n",
    "lit_model = LitClassifier(model)\n",
    "trainer = lightning.Trainer(max_epochs=10, accelerator=\"gpu\")\n",
    "trainer.fit(model=lit_model, train_dataloaders=train_loader, val_dataloaders=valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3361eca4-0b35-4e06-915b-b13c5f40e4c7",
   "metadata": {},
   "source": [
    "### Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "cfae5594-e3b9-4ffa-80ad-7f5d4098c2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from course_intro_ocr_t1.metrics import dump_results_dict, measure_crop_accuracy, iou_relative_quads\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6ba42bf3-575e-4dca-8919-d1fa715c36c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from course_intro_ocr_t1.metrics import dump_results_dict, measure_crop_accuracy, iou_relative_quads\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "f6390e81-4446-481f-ba64-f3df1531b13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(img, return_corners=True):\n",
    "\n",
    "    img = transforms.ToTensor()(img)\n",
    "    img_size = img.size()[1:]\n",
    "    img = img.unsqueeze(0)\n",
    "    img = transforms.Resize((256, 256))(img).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        mask_ = model(img)\n",
    "    \n",
    "    mask = (mask_ > 0)\n",
    "    mask = transforms.Resize((img_size[0], img_size[1]))(mask).cpu().squeeze().numpy().astype(np.uint8)\n",
    "    contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    contour = max(contours, key=cv.contourArea)\n",
    "\n",
    "    if contours:\n",
    "        contour = max(contours, key=cv.contourArea)\n",
    "        x, y = contour[:, 0, 0], contour[:, 0, 1]\n",
    "\n",
    "        corners_i = np.array([np.argmin(x + y), np.argmin(-x + y), np.argmax(x + y), np.argmax(-x + y)])\n",
    "        corners = np.array([x[corners_i], y[corners_i]]).T.astype(float)\n",
    "    \n",
    "    y, x = img_size[0], img_size[1]\n",
    "\n",
    "    normalization = np.array([x, y] * 4, dtype=np.float64).reshape(4, 2)\n",
    "    \n",
    "\n",
    "    for i in range(len(corners)):\n",
    "        corners[i][0] /= normalization[i][0]\n",
    "        corners[i][1] /= normalization[i][1] \n",
    "    \n",
    "    if return_corners:\n",
    "        return corners\n",
    "    else:\n",
    "        return corners, mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "44152f76-df93-4a41-8dc1-a1894cfaf326",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|██████████                                                                                                                                                              | 3/50 [00:01<00:27,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|█████████████████████████████████████████████████████████████████████████▍                                                                                             | 22/50 [00:21<00:33,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|████████████████████████████████████████████████████████████████████████████████████████████████▊                                                                      | 29/50 [00:31<00:28,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                              | 41/50 [00:41<00:05,  1.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n",
      "max() arg is an empty sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [00:49<00:00,  1.00it/s]\n"
     ]
    }
   ],
   "source": [
    "results_dict = {}\n",
    "for dp in tqdm(data_packs):\n",
    "    for i in range(len(dp)):\n",
    "        if dp[i].is_test_split():\n",
    "            try:\n",
    "                results_dict[dp[i].unique_key] = crop(np.array(dp[i].image))\n",
    "            except Exception as exc:\n",
    "                # Для пропущенных в словаре ключей в метриках автоаматически засчитается IoU=0\n",
    "                print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d647f14-1615-4125-9792-53f8f6e69739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740043a5-9a8f-4890-8ed2-24cfc75c4b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6908d15e-5bfd-4ca7-b78f-4e9f52bd386d",
   "metadata": {},
   "source": [
    "# Сохраним результаты и измерим точность\n",
    "Результаты - словарь с ключем DataItem.unique_key() и значением предсказанным quadrangle в относительных единицах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abace615-bc4b-433e-a07e-400c309cf9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "a91cde35-ada3-48ac-819d-c79c43c5e03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_results_dict(results_dict, Path() / 'pred.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "c7b20a48-ad36-4a99-92eb-9bec3364cfb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = measure_crop_accuracy(\n",
    "    Path() / 'pred.json',\n",
    "    Path() / 'gt.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "0ee8b4cb-2a9f-4fe2-8bf9-d088c3e973e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность кропа: 0.8365\n"
     ]
    }
   ],
   "source": [
    "print(\"Точность кропа: {:1.4f}\".format(acc))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
