{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8505435,"sourceType":"datasetVersion","datasetId":5076663},{"sourceId":8505591,"sourceType":"datasetVersion","datasetId":5076768},{"sourceId":8505595,"sourceType":"datasetVersion","datasetId":5076772},{"sourceId":8506401,"sourceType":"datasetVersion","datasetId":5077353}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"code","source":"from torchvision.models import resnet18","metadata":{"execution":{"iopub.status.busy":"2024-10-12T06:40:04.430098Z","iopub.execute_input":"2024-10-12T06:40:04.430981Z","iopub.status.idle":"2024-10-12T06:40:11.099992Z","shell.execute_reply.started":"2024-10-12T06:40:04.430944Z","shell.execute_reply":"2024-10-12T06:40:11.099213Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install lmdb","metadata":{"execution":{"iopub.status.busy":"2024-10-12T06:40:21.537000Z","iopub.execute_input":"2024-10-12T06:40:21.537871Z","iopub.status.idle":"2024-10-12T06:40:35.126434Z","shell.execute_reply.started":"2024-10-12T06:40:21.537835Z","shell.execute_reply":"2024-10-12T06:40:35.125425Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting lmdb\n  Downloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)\nDownloading lmdb-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: lmdb\nSuccessfully installed lmdb-1.5.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pytorch_metric_learning","metadata":{"execution":{"iopub.status.busy":"2024-10-12T06:41:15.835616Z","iopub.execute_input":"2024-10-12T06:41:15.836009Z","iopub.status.idle":"2024-10-12T06:41:28.742129Z","shell.execute_reply.started":"2024-10-12T06:41:15.835978Z","shell.execute_reply":"2024-10-12T06:41:28.741166Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting pytorch_metric_learning\n  Downloading pytorch_metric_learning-2.6.0-py3-none-any.whl.metadata (17 kB)\nRequirement already satisfied: numpy<2.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_metric_learning) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from pytorch_metric_learning) (1.2.2)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_metric_learning) (2.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from pytorch_metric_learning) (4.66.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->pytorch_metric_learning) (2024.2.0)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch_metric_learning) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch_metric_learning) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->pytorch_metric_learning) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->pytorch_metric_learning) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->pytorch_metric_learning) (1.3.0)\nDownloading pytorch_metric_learning-2.6.0-py3-none-any.whl (119 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.3/119.3 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pytorch_metric_learning\nSuccessfully installed pytorch_metric_learning-2.6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torch import nn\nimport cv2\nimport numpy as np\nimport os\nfrom pathlib import Path\nfrom pytorch_metric_learning import losses\nfrom matplotlib import pyplot as plt\nimport torch.nn.functional as F\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:27:58.515677Z","iopub.execute_input":"2024-10-12T10:27:58.516422Z","iopub.status.idle":"2024-10-12T10:27:58.522166Z","shell.execute_reply.started":"2024-10-12T10:27:58.516381Z","shell.execute_reply":"2024-10-12T10:27:58.521234Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path\n\ndef evaluate(gt_path, pred_path):\n    gt = dict()\n    with open(gt_path) as gt_f:\n        for line in gt_f:\n            name, cls = line.strip().split()\n            gt[name] = cls\n    \n    n_good = 0\n    n_all = len(gt)\n    with open(pred_path) as pred_f:\n        for line in pred_f:\n            name, cls = line.strip().split()\n            if cls == gt[name]:\n                n_good += 1\n    \n    return n_good / n_all","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:27:59.113860Z","iopub.execute_input":"2024-10-12T10:27:59.114763Z","iopub.status.idle":"2024-10-12T10:27:59.121237Z","shell.execute_reply.started":"2024-10-12T10:27:59.114726Z","shell.execute_reply":"2024-10-12T10:27:59.120233Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"root = '/kaggle/input/chinese'\ntrain_path = os.path.join(root, 'train.lmdb')\ntest_path = os.path.join(root, 'test.lmdb')\ngt_path = '/kaggle/input/directory_gt/gt.txt'\npred_path = '/kaggle/working/pred.txt'","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:28:00.328214Z","iopub.execute_input":"2024-10-12T10:28:00.328951Z","iopub.status.idle":"2024-10-12T10:28:00.333732Z","shell.execute_reply.started":"2024-10-12T10:28:00.328916Z","shell.execute_reply":"2024-10-12T10:28:00.332766Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"from itertools import permutations\nimport zipfile\nfrom typing import Optional, List\nfrom pathlib import Path\nimport numpy as np\nfrom collections import defaultdict, Counter\nimport lmdb\n\n\nclass Vocabulary:\n    def __init__(self, classes):\n        self.classes = sorted(set(classes))\n        self._class_to_index = dict((cls, idx) for idx, cls in enumerate(self.classes))\n    \n    def class_by_index(self, idx: int) -> str:\n        return self.classes[idx]\n\n    def index_by_class(self, cls: str) -> int:\n        return self._class_to_index[cls]\n    \n    def num_classes(self) -> int:\n        return len(self.classes)\n\n\nclass ArchivedHWDBReader:\n    def __init__(self, path: Path):\n        self.path = path\n        self.archive = None\n    \n    def open(self):\n        self.archive = zipfile.ZipFile(self.path)\n    \n    def namelist(self):\n        return self.archive.namelist()\n    \n    def decode_image(self, name):\n        sample = self.archive.read(name)\n        buf = np.asarray(bytearray(sample), dtype='uint8')\n        return cv2.imdecode(buf, cv2.IMREAD_GRAYSCALE)\n    \n    def close(self):\n        self.archive.close()\n    \n    def __enter__(self):\n        self.open()\n        return self\n    \n    def __exit__(self, exc_type, exc_value, traceback):\n        self.close()\n\n\nGB = 2**30\nclass LMDBReader:\n    def __init__(self, path: Path):\n        self.path = path\n        self.env = None\n        self.namelist_ = []\n    \n    def open(self):\n        self.env = lmdb.open(self.path, \n                             map_size=GB * 16,\n                             lock=False, \n                             subdir=False, \n                             readonly=True)\n        self.namelist_ = []\n        with self.env.begin(buffers=True) as txn:\n            cursor = txn.cursor()\n            for key, _ in cursor:\n                key = bytes(key).decode('utf-8')\n                self.namelist_.append(key)\n    \n    def namelist(self):\n        return self.namelist_\n    \n    def decode_image(self, name):\n        key = name.encode('utf-8')\n        with self.env.begin() as txn:\n            sample = txn.get(key)\n        buf = np.frombuffer(sample, dtype='uint8')\n        return cv2.imdecode(buf, cv2.IMREAD_GRAYSCALE)\n    \n    def close(self):\n        self.env.close()\n    \n    def __enter__(self):\n        self.open()\n        return self\n    \n    def __exit__(self, exc_type, exc_value, traceback):\n        self.close()\n\n\nclass HWDBDatasetHelper:\n    def __init__(self, reader, prefix='Train', vocabulary: Optional[Vocabulary]=None, namelist: Optional[List[str]]=None):\n        self.reader = reader\n        self.prefix = prefix\n        self.index = defaultdict(list)\n        self.counter = Counter()\n        self.namelist = namelist\n        if self.namelist is None:\n            self.namelist = list(filter(lambda x: self.prefix in x, self.reader.namelist()))\n        self.vocabulary = vocabulary\n        self._build_index()\n    \n    def get_item(self, idx):\n        name = self.namelist[idx]\n        return self.reader.decode_image(name), \\\n            self.vocabulary.index_by_class(HWDBDatasetHelper._get_class(name))\n    \n    def size(self):\n        return len(self.namelist)\n\n    def get_all_class_items(self, idx):\n        cls = self.vocabulary.class_by_index(idx)\n        return self.index[cls]\n    \n    def most_common_classes(self, n=None):\n        return self.counter.most_common(n)\n    \n    def train_val_split(self, train_part=0.8, seed=42):\n        rnd = np.random.default_rng(seed)\n        permutation = rnd.permutation(len(self.namelist))\n        train_part = int(len(permutation) * train_part)\n        train_names = [self.namelist[idx] for idx in permutation[:train_part]]\n        val_names = [self.namelist[idx] for idx in permutation[train_part:]]\n\n        return HWDBDatasetHelper(self.reader, self.prefix, self.vocabulary, train_names),\\\n            HWDBDatasetHelper(self.reader, self.prefix, self.vocabulary, val_names)\n    \n    @staticmethod\n    def _get_class(name):\n        return Path(name).parent.name\n    \n    def _build_index(self):\n        classes = set()\n        for idx, name in enumerate(self.namelist):\n            cls = HWDBDatasetHelper._get_class(name)\n            classes.add(cls)\n            self.index[cls].append(idx)\n            self.counter.update([cls])\n        \n        if self.vocabulary is None:\n            self.vocabulary = Vocabulary(classes)\n\nclass HWDBDataset(Dataset):\n    def __init__(self, helper: HWDBDatasetHelper):\n        self.helper = helper\n    \n    def __len__(self):\n        return self.helper.size()\n    \n    def __getitem__(self, idx):\n        img, label = self.helper.get_item(idx)\n        img = cv2.resize(img, (128, 128))\n        img = torch.tensor(img, dtype=torch.float32).unsqueeze(0)\n        img = (img - 127.5) / 255.\n        return img, label\n","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:29:48.180788Z","iopub.execute_input":"2024-10-12T10:29:48.181159Z","iopub.status.idle":"2024-10-12T10:29:48.213343Z","shell.execute_reply.started":"2024-10-12T10:29:48.181128Z","shell.execute_reply":"2024-10-12T10:29:48.212277Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"train_reader = LMDBReader(train_path)\ntrain_reader.open()\ntrain_helper = HWDBDatasetHelper(train_reader)\ntrain_helper, val_helper = train_helper.train_val_split()","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:29:51.422235Z","iopub.execute_input":"2024-10-12T10:29:51.422977Z","iopub.status.idle":"2024-10-12T10:31:09.000919Z","shell.execute_reply.started":"2024-10-12T10:29:51.422942Z","shell.execute_reply":"2024-10-12T10:31:09.000081Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"code","source":"train_dataset = HWDBDataset(train_helper)\nval_dataset = HWDBDataset(val_helper)\ntrain_loader = DataLoader(train_dataset, batch_size=512, shuffle=True, drop_last=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=2048, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:31:09.002505Z","iopub.execute_input":"2024-10-12T10:31:09.002803Z","iopub.status.idle":"2024-10-12T10:31:09.734630Z","shell.execute_reply.started":"2024-10-12T10:31:09.002778Z","shell.execute_reply":"2024-10-12T10:31:09.733753Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"class CustomResNet(nn.Module):\n    def __init__(self, embedding_size=512):\n        super().__init__()\n        self.resnet = resnet18()\n        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, embedding_size)\n#         self.resnet.fc = nn.Linear(num_features, embedding_size)\n    \n    def forward(self, x):\n        x = x.expand(-1, 3, -1, -1)\n        return self.resnet(x)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:48:23.410388Z","iopub.execute_input":"2024-10-12T10:48:23.410747Z","iopub.status.idle":"2024-10-12T10:48:23.417399Z","shell.execute_reply.started":"2024-10-12T10:48:23.410718Z","shell.execute_reply":"2024-10-12T10:48:23.416340Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"code","source":"from pytorch_metric_learning import losses\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = CustomResNet()\nmodel = model.to(device)\noptim = torch.optim.AdamW(model.parameters(), lr=0.001)\nloss_fn = losses.ArcFaceLoss(num_classes=train_helper.vocabulary.num_classes(), embedding_size=512).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:48:23.963855Z","iopub.execute_input":"2024-10-12T10:48:23.964212Z","iopub.status.idle":"2024-10-12T10:48:24.259514Z","shell.execute_reply.started":"2024-10-12T10:48:23.964180Z","shell.execute_reply":"2024-10-12T10:48:24.258560Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"def run_validation(val_loader: DataLoader, model: nn.Module, n_steps=None):\n    model.eval()\n    n_good = 0\n    n_all = 0\n    wrapper = lambda x: x\n    if n_steps is None:\n        n_steps = len(val_loader)\n        wrapper = tqdm\n    \n    with torch.no_grad():\n        for batch, (X, y) in enumerate(wrapper(val_loader)):\n            if batch == n_steps:\n                break\n            logits = model(X.to(torch.float32).to(device))\n            X = model(X.to(torch.float32).to(device))\n            logits = loss_fn.get_logits(X)\n            classes = torch.argmax(logits, dim=1).cpu().numpy()\n            n_good += sum(classes == y.cpu().numpy())\n            n_all += len(classes)\n    \n    return n_good / n_all","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:48:26.618364Z","iopub.execute_input":"2024-10-12T10:48:26.618727Z","iopub.status.idle":"2024-10-12T10:48:26.627315Z","shell.execute_reply.started":"2024-10-12T10:48:26.618699Z","shell.execute_reply":"2024-10-12T10:48:26.626337Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"for epoch in range(3):\n    print(f'Epoch {epoch}:')\n    for batch, (X, y) in enumerate(tqdm(train_loader)):\n        model.train()\n        \n        logits = model(X.to(torch.float32).to(device))\n        loss = loss_fn(logits, y.to(torch.long).to(device))\n        \n        optim.zero_grad()\n        loss.backward()\n        optim.step()\n\n    torch.save(model.state_dict(), f'my_epoch{epoch}.pth')\n    \n    accuracy = run_validation(val_loader, model)\n    print(f'accuracy: {accuracy}')","metadata":{"execution":{"iopub.status.busy":"2024-10-12T10:48:35.767589Z","iopub.execute_input":"2024-10-12T10:48:35.768240Z","iopub.status.idle":"2024-10-12T12:16:09.841602Z","shell.execute_reply.started":"2024-10-12T10:48:35.768202Z","shell.execute_reply":"2024-10-12T12:16:09.840384Z"},"trusted":true},"execution_count":101,"outputs":[{"name":"stdout","text":"Epoch 0:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5036/5036 [24:33<00:00,  3.42it/s]\n100%|██████████| 315/315 [04:37<00:00,  1.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9388590602985686\nEpoch 1:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5036/5036 [24:33<00:00,  3.42it/s]\n100%|██████████| 315/315 [04:37<00:00,  1.14it/s]\n","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9368159613036741\nEpoch 2:\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 5036/5036 [24:33<00:00,  3.42it/s]\n100%|██████████| 315/315 [04:37<00:00,  1.13it/s]","output_type":"stream"},{"name":"stdout","text":"accuracy: 0.9577914673856555\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"test_reader = LMDBReader(test_path)\ntest_reader.open()\ntest_helper = HWDBDatasetHelper(test_reader, prefix='Test')\ntest_dataset = HWDBDataset(test_helper)\ntest_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=0)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:22:38.999522Z","iopub.execute_input":"2024-10-12T12:22:38.999958Z","iopub.status.idle":"2024-10-12T12:22:48.242847Z","shell.execute_reply.started":"2024-10-12T12:22:38.999921Z","shell.execute_reply":"2024-10-12T12:22:48.241995Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"code","source":"preds = []\nmodel.eval()\nwith torch.no_grad():\n    for X, _ in tqdm(test_loader):\n        x = model(X.to(torch.float32).to(device))\n        logits = loss_fn.get_logits(x)\n        classes = torch.argmax(logits, dim=1).cpu().numpy()\n        preds.extend(classes)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:22:48.244387Z","iopub.execute_input":"2024-10-12T12:22:48.244673Z","iopub.status.idle":"2024-10-12T12:28:19.912561Z","shell.execute_reply.started":"2024-10-12T12:22:48.244647Z","shell.execute_reply":"2024-10-12T12:28:19.911645Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stderr","text":"100%|██████████| 1517/1517 [05:31<00:00,  4.57it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(pred_path, 'w', encoding=\"utf-8\") as f_pred:\n    for idx, pred in enumerate(preds):\n        name = test_helper.namelist[idx]\n        cls = train_helper.vocabulary.class_by_index(pred)\n        print(name, cls, file=f_pred)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:28:27.227533Z","iopub.execute_input":"2024-10-12T12:28:27.227894Z","iopub.status.idle":"2024-10-12T12:28:28.555866Z","shell.execute_reply.started":"2024-10-12T12:28:27.227863Z","shell.execute_reply":"2024-10-12T12:28:28.554852Z"},"trusted":true},"execution_count":106,"outputs":[]},{"cell_type":"code","source":"gt_path = '/kaggle/input/gttttt/gt.txt'\nevaluate(gt_path, pred_path)","metadata":{"execution":{"iopub.status.busy":"2024-10-12T12:28:28.557633Z","iopub.execute_input":"2024-10-12T12:28:28.557935Z","iopub.status.idle":"2024-10-12T12:28:30.124747Z","shell.execute_reply.started":"2024-10-12T12:28:28.557910Z","shell.execute_reply":"2024-10-12T12:28:30.123812Z"},"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"0.9444472346601452"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}